{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b68d7bb4",
      "metadata": {
        "id": "b68d7bb4"
      },
      "source": [
        "## Packages and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hDnIEHOKB8LD",
      "metadata": {
        "id": "hDnIEHOKB8LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59fb0db5-cd09-4865-ed69-850773ec2677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jedi in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi) (0.8.4)\n",
            "Requirement already satisfied: snntorch in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.4.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.26.4)\n",
            "Requirement already satisfied: nir in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.0.4)\n",
            "Requirement already satisfied: nirtorch in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nir->snntorch) (3.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->snntorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->snntorch) (1.3.0)\n",
            "Requirement already satisfied: brevitas in /usr/local/lib/python3.10/dist-packages (0.10.3)\n",
            "Requirement already satisfied: dependencies==2.0.1 in /usr/local/lib/python3.10/dist-packages (from brevitas) (2.0.1)\n",
            "Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.10/dist-packages (from brevitas) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brevitas) (24.1)\n",
            "Requirement already satisfied: setuptools<70.0 in /usr/local/lib/python3.10/dist-packages (from brevitas) (69.5.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from brevitas) (1.13.2)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from brevitas) (2.4.1+cu121)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from brevitas) (4.12.2)\n",
            "Requirement already satisfied: unfoldNd in /usr/local/lib/python3.10/dist-packages (from brevitas) (0.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->brevitas) (3.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->brevitas) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->brevitas) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->brevitas) (2024.6.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->brevitas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->brevitas) (2.1.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ],
      "source": [
        "!pip install jedi\n",
        "!pip install snntorch\n",
        "!pip install brevitas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "import snntorch as snn\n",
        "from brevitas.nn import QuantLinear\n",
        "from brevitas.nn import QuantLinear\n",
        "from brevitas.quant import Int8WeightPerTensorFixedPoint\n",
        "from brevitas.core.quant import QuantType\n",
        "from brevitas.nn import QuantLinear\n",
        "from snntorch import functional as SF\n",
        "from snntorch import functional as SF\n",
        "import brevitas.nn as qnn\n",
        "\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization"
      ],
      "metadata": {
        "id": "KxYue0IBDsZC"
      },
      "id": "KxYue0IBDsZC"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "class StateQuant(torch.autograd.Function):\n",
        "    \"\"\"Wrapper function for state quantization.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input_, levels):\n",
        "        device = input_.device\n",
        "        levels = levels.to(device)\n",
        "        size = input_.size()\n",
        "        input_ = input_.flatten()\n",
        "\n",
        "        # Broadcast levels along a new dimension equal to the number of levels\n",
        "        input_expanded = input_.unsqueeze(-1).repeat(1, levels.size(0))\n",
        "\n",
        "        # Find the closest valid quantization state\n",
        "        differences = torch.abs(levels - input_expanded)\n",
        "        idx_match = torch.argmin(differences, dim=-1)\n",
        "        quant_tensor = levels[idx_match]\n",
        "\n",
        "        return quant_tensor.reshape(size)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # Straight Through Estimator (STE)\n",
        "        grad_input = grad_output.clone()\n",
        "        return grad_input, None\n",
        "\n",
        "def state_quant(num_bits=8, uniform=True, thr_centered=True, threshold=1,\n",
        "                lower_limit=0, upper_limit=0.2, multiplier=None):\n",
        "    \"\"\"Generate a quantization function with specified parameters.\"\"\"\n",
        "    num_levels = 2 ** num_bits  # Total number of quantization levels\n",
        "\n",
        "    if uniform:\n",
        "        # Uniform quantization\n",
        "        levels = torch.linspace(\n",
        "            -threshold * (1 + lower_limit),\n",
        "            threshold * (1 + upper_limit),\n",
        "            num_levels\n",
        "        )\n",
        "    else:\n",
        "        # Non-uniform quantization\n",
        "        if multiplier is None:\n",
        "            # Default values based on number of bits\n",
        "            multiplier = 0.05 + 0.9 * (num_bits - 1) / 15\n",
        "\n",
        "        if thr_centered:\n",
        "            # Centered around threshold\n",
        "            max_val = threshold * (1 + upper_limit)\n",
        "            min_val = -threshold * (1 + lower_limit)\n",
        "        else:\n",
        "            # Centered around zero\n",
        "            max_val = threshold + threshold * upper_limit\n",
        "            min_val = -threshold - threshold * lower_limit\n",
        "\n",
        "        range_vals = torch.logspace(\n",
        "            start=-multiplier * (num_levels - 1),\n",
        "            end=0,\n",
        "            steps=num_levels,\n",
        "            base=10\n",
        "        )\n",
        "        levels = min_val + range_vals * (max_val - min_val)\n",
        "\n",
        "    def inner(x):\n",
        "        return StateQuant.apply(x, levels)\n",
        "\n",
        "    return inner\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    num_bits = 5\n",
        "    q_func = state_quant(num_bits=num_bits, uniform=True, threshold=5)\n",
        "\n",
        "    # Sample input tensor\n",
        "    x = torch.rand(10, 10) * 10 - 5  # Random values between -5 and 5\n",
        "    quant_x = q_func(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "aWiheFA7eATf"
      },
      "id": "aWiheFA7eATf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the quantization function for state variables\n",
        "quant_func = state_quant(num_bits=6, uniform=True, threshold=1)"
      ],
      "metadata": {
        "id": "91QpyEeHOSUv"
      },
      "id": "91QpyEeHOSUv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight Constraints"
      ],
      "metadata": {
        "id": "k_SA4ZhZD54w"
      },
      "id": "k_SA4ZhZD54w"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to apply constraints on weights\n",
        "def apply_weight_constraints(model):\n",
        "    # Constraint: Positive integer weights and specific connections set to zero\n",
        "    with torch.no_grad():\n",
        "        # Constrain the first layer weights to be positive and integer\n",
        "        # model.fc1.weight.data = torch.clamp(model.fc1.weight.data, min=0)\n",
        "        # model.fc1.weight.data = model.fc1.weight.data.round()\n",
        "\n",
        "        # Apply specific constraints to the first layer weights\n",
        "        model.fc1.weight.data[1, 0] = 0  # input0 -> neuron1\n",
        "        model.fc1.weight.data[2, 0] = 0  # input0 -> neuron2\n",
        "        model.fc1.weight.data[0, 1] = 0  # input1 -> neuron0\n",
        "        model.fc1.weight.data[2, 1] = 0  # input1 -> neuron2\n",
        "        model.fc1.weight.data[0, 2] = 0  # input2 -> neuron0\n",
        "        model.fc1.weight.data[1, 2] = 0  # input2 -> neuron1\n",
        "\n",
        "        # Set biases to 0\n",
        "        model.fc1.bias.data.fill_(0)\n",
        "        model.fc2.bias.data.fill_(0)\n",
        "\n",
        "        # Constrain the second layer weights to be positive and integer\n",
        "        # model.fc2.weight.data = torch.clamp(model.fc2.weight.data, min=0)\n",
        "        # # model.fc2.weight.data = model.fc2.weight.data.round()"
      ],
      "metadata": {
        "id": "3Y-LiD71u8WA"
      },
      "id": "3Y-LiD71u8WA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gray Code Dataset"
      ],
      "metadata": {
        "id": "J3eXeAVSEQ7h"
      },
      "id": "J3eXeAVSEQ7h"
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the Gray code sequence\n",
        "gray_codes = [\n",
        "    [0, 0, 0],  # 0\n",
        "    [0, 0, 1],  # 1\n",
        "    [0, 1, 1],  # 2\n",
        "    [0, 1, 0],  # 3\n",
        "    [1, 1, 0],  # 4\n",
        "    [1, 1, 1],  # 5\n",
        "    [1, 0, 1],  # 6\n",
        "    [1, 0, 0],   # 7\n",
        "    [0, 0, 0]  # 0 (looping back)\n",
        "]\n",
        "\n",
        "\n",
        "def get_gray_code_index(tensor_vector):\n",
        "\n",
        "    if tensor_vector.dim() == 1:  # Single vector case\n",
        "        vector_list = tensor_vector.tolist()  # Convert tensor to list\n",
        "        for i, code in enumerate(gray_codes):\n",
        "            if code == vector_list:\n",
        "                return i\n",
        "        return -1  # Return -1 if not found\n",
        "\n",
        "    elif tensor_vector.dim() == 2:  # Matrix case (batch of vectors)\n",
        "        indices = []\n",
        "        for row in tensor_vector:\n",
        "            vector_list = row.tolist()  # Convert each row (vector) to list\n",
        "            found = False\n",
        "            for i, code in enumerate(gray_codes):\n",
        "                if code == vector_list:\n",
        "                    indices.append(i)\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                indices.append(-1)  # If the vector is not found, append -1\n",
        "        return indices  # Return tensor of indices\n",
        "\n",
        "# Function to get Gray codes for a list of indices\n",
        "def get_gray_codes_from_indices(indices):\n",
        "    # Create a list to hold the Gray codes corresponding to the indices\n",
        "    gray_code_list = [gray_codes[i] for i in indices]\n",
        "\n",
        "    # Convert the list of Gray codes to a tensor\n",
        "    gray_code_tensor = torch.tensor(gray_code_list)\n",
        "\n",
        "    return gray_code_tensor\n",
        "\n",
        "max_index = len(gray_codes)-1  # Total number of Gray codes (9 in this case)\n",
        "# Function to increment indices by 1, wrapping around if necessary\n",
        "def increment_indices(indices, max_index):\n",
        "    incremented_indices = [(i + 1) % max_index for i in indices]\n",
        "    return incremented_indices\n",
        "\n",
        "def decrement_indices(indices, max_index=8):\n",
        "    decremented_indices = [(i - 1) % max_index for i in indices]\n",
        "    return decremented_indices\n",
        "\n",
        "\n",
        "\n",
        "# Create input-output pairs for training\n",
        "X = torch.tensor(gray_codes[:-1], dtype=torch.float32)  # Inputs: 000 to 110\n",
        "y = torch.tensor(gray_codes[1:], dtype=torch.float32)   # Outputs: 001 to 100 (next Gray code)\n",
        "\n",
        "# Replicate X and y to make a bigger dataset\n",
        "replication_factor = 100  # Number of times to replicate the dataset\n",
        "X_replicated = X.repeat((replication_factor, 1))\n",
        "y_replicated = y.repeat((replication_factor, 1))\n",
        "\n",
        "# # Shuffle the dataset\n",
        "# indices = torch.randperm(X_replicated.size(0))\n",
        "# X_shuffled = X_replicated[indices]\n",
        "# y_shuffled = y_replicated[indices]\n",
        "\n",
        "# Create DataLoader\n",
        "# dataset = TensorDataset(X_shuffled, y_shuffled)\n",
        "# train_loader = DataLoader(dataset, batch_size=18, shuffle=True)\n",
        "dataset = TensorDataset(X_replicated, y_replicated)\n",
        "train_loader = DataLoader(dataset, batch_size=8, shuffle=False)\n"
      ],
      "metadata": {
        "id": "pk5m7GHTEPjz"
      },
      "id": "pk5m7GHTEPjz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SNN: model and training"
      ],
      "metadata": {
        "id": "N7lc6GouEBKW"
      },
      "id": "N7lc6GouEBKW"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the model\n",
        "class NetSNN(nn.Module):\n",
        "    def __init__(self, timesteps, hidden, beta, quant_bit_width=8):\n",
        "        super().__init__()\n",
        "        self.timesteps = timesteps\n",
        "        self.hidden = hidden\n",
        "        self.beta = beta\n",
        "\n",
        "        # Corrected Quantized linear layers using Brevitas\n",
        "        self.fc1 = QuantLinear(3, hidden, bias=True, bit_width=quant_bit_width,\n",
        "                               weight_quant_type=QuantType.INT, weight_bit_width=quant_bit_width)\n",
        "        # Spiking neuron layers with quantized state variables\n",
        "        self.lif1 = snn.Leaky(beta=self.beta)\n",
        "\n",
        "        self.fc2 = QuantLinear(hidden, 3, bias=True, bit_width=quant_bit_width,\n",
        "                               weight_quant_type=QuantType.INT, weight_bit_width=quant_bit_width)\n",
        "        self.lif2 = snn.Leaky(beta=self.beta)\n",
        "\n",
        "    def forward(self, x):\n",
        "        decay_value=0.01\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        spk_recording = []\n",
        "        decay_value1 =0.01\n",
        "        indices = get_gray_code_index(x)\n",
        "        for step in range(self.timesteps):\n",
        "            x=get_gray_codes_from_indices(indices)\n",
        "            x=x.float()\n",
        "            cur1 = self.fc1(x)\n",
        "            if step != 0:\n",
        "              mem1 = torch.where(mem1 < decay_value, cur1, mem1 - decay_value)\n",
        "              self.lif1.mem = mem1\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "            cur2 = self.fc2(spk1)\n",
        "            if step != 0:\n",
        "              mem2 = torch.where(mem2 < decay_value, cur2, mem2 - decay_value)\n",
        "              self.lif2.mem = mem2\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            spk_recording.append(spk2)\n",
        "            # if step % 2 == 0:\n",
        "            # indices=increment_indices(indices, max_index)\n",
        "            indices=decrement_indices(indices)\n",
        "            # print(f\"mem1: {indices }\")\n",
        "        return torch.stack(spk_recording)\n",
        "\n",
        "# Instantiate the model\n",
        "num_steps = 4  # Number of time steps\n",
        "hidden = 3     # Number of hidden neurons\n",
        "beta = 0.999     # Membrane potential decay rate\n",
        "model = NetSNN(timesteps=num_steps, hidden=hidden, beta=beta).to(device)\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "loss_function = nn.MSELoss()  # Use MSE as it's suitable for regression-type tasks like this\n",
        "\n",
        "best_loss = float('inf')  # Set initial best loss to infinity\n",
        "best_model_path = \"best_model.pth\"  # File path to save the best model\n",
        "\n",
        "epoch_loss = 100\n",
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "accuracy=0\n",
        "while accuracy<100:\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "      for data, targets in train_loader:\n",
        "          data = data.to(device)\n",
        "          targets = targets.to(device)\n",
        "\n",
        "          # apply_weight_constraints(model)\n",
        "\n",
        "          spk = model(data)\n",
        "          # Take the mean across the time steps\n",
        "          output = spk[-1] #.mean(dim=0)\n",
        "          loss_val = loss_function(output, targets)  # apply loss\n",
        "          optimizer.zero_grad()  # zero out gradients\n",
        "          loss_val.backward()  # calculate gradients\n",
        "          optimizer.step()  # update weights\n",
        "\n",
        "          # Apply constraints after each update\n",
        "          apply_weight_constraints(model)\n",
        "\n",
        "      # Save the model if the current epoch's loss is lower than the best loss\n",
        "      if epoch_loss > loss_val.item() or epoch==0:\n",
        "        epoch_loss = loss_val.item()\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"Epoch {epoch}: Saving model with loss {epoch_loss:.4f}\")\n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "          print(f'Epoch {epoch}, Loss: {loss_val.item()}')\n",
        "\n",
        "  # Testing and Evaluation loop\n",
        "  model.load_state_dict(torch.load(best_model_path))\n",
        "  model.eval()\n",
        "  correct_predictions = 0\n",
        "  total_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for data, targets in train_loader:\n",
        "          data = data.to(device)\n",
        "          targets = targets.to(device)\n",
        "\n",
        "          spk = model(data)\n",
        "          # Take the mean across the time steps\n",
        "          output = spk[-1] #.mean(dim=0)\n",
        "          predicted = output #.round()  # Round to the nearest integer (0 or 1)\n",
        "\n",
        "          correct_predictions += (predicted == targets).all(dim=1).sum().item()\n",
        "          total_predictions += targets.size(0)\n",
        "\n",
        "          # print(f\"Input: {data.cpu().numpy()}, Predicted: {predicted.cpu().numpy()}, Target: {targets.cpu().numpy()}\")\n",
        "\n",
        "  accuracy = correct_predictions / total_predictions * 100\n",
        "  print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNdALUV2Jtmf",
        "outputId": "6ee27ea2-c1bb-4edb-9124-0550c382d4c0"
      },
      "id": "nNdALUV2Jtmf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Saving model with loss 0.3750\n",
            "Epoch 0, Loss: 0.375\n",
            "Epoch 1: Saving model with loss 0.2083\n",
            "Epoch 7: Saving model with loss 0.1667\n",
            "Epoch 10, Loss: 0.1666666716337204\n",
            "Epoch 15: Saving model with loss 0.1250\n",
            "Epoch 20, Loss: 0.125\n",
            "Epoch 24: Saving model with loss 0.0833\n",
            "Epoch 30, Loss: 0.0833333358168602\n",
            "Epoch 40, Loss: 0.0833333358168602\n",
            "Epoch 50, Loss: 0.0833333358168602\n",
            "Epoch 60, Loss: 0.0833333358168602\n",
            "Epoch 70, Loss: 0.0833333358168602\n",
            "Epoch 80, Loss: 0.0833333358168602\n",
            "Epoch 86: Saving model with loss 0.0000\n",
            "Epoch 90, Loss: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-79ad095d25f4>:178: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "YG26ndNmEXzz"
      },
      "id": "YG26ndNmEXzz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing and Evaluation loop\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "model.eval()\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, targets in train_loader:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        spk = model(data)\n",
        "        # Take the mean across the time steps\n",
        "        output = spk[-1] #.mean(dim=0)\n",
        "        predicted = output #.round()  # Round to the nearest integer (0 or 1)\n",
        "\n",
        "        correct_predictions += (predicted == targets).all(dim=1).sum().item()\n",
        "        total_predictions += targets.size(0)\n",
        "\n",
        "        # print(f\"Input: {data.cpu().numpy()}, Predicted: {predicted.cpu().numpy()}, Target: {targets.cpu().numpy()}\")\n",
        "\n",
        "accuracy = correct_predictions / total_predictions * 100\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9H4drd9tELB",
        "outputId": "6eba52fb-31cb-4879-e5d3-a03c0986eeee"
      },
      "id": "t9H4drd9tELB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-8cb227cb8b47>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the properties of the spiking neurons in the model\n",
        "def print_snn_properties(model):\n",
        "    for name, layer in model.named_modules():\n",
        "        if isinstance(layer, snn.Leaky):\n",
        "            print(f\"Properties of {name}:\")\n",
        "            print(f\"  - Leaky (beta): {layer.beta}\")  # Membrane potential decay rate\n",
        "            # Check if threshold and refractory period attributes exist\n",
        "            threshold = getattr(layer, 'threshold', None)\n",
        "            refractory_period = getattr(layer, 'refractory', None)\n",
        "            if threshold is not None:\n",
        "                print(f\"  - Threshold: {threshold}\")\n",
        "            else:\n",
        "                print(f\"  - Threshold: Not specified in this layer.\")\n",
        "\n",
        "            print()\n",
        "\n",
        "# Call the function to print properties of the spiking neurons\n",
        "print_snn_properties(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APjAw8WkzlLG",
        "outputId": "d102dced-2ef6-4730-a825-2189d636d45a"
      },
      "id": "APjAw8WkzlLG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Properties of lif1:\n",
            "  - Leaky (beta): 0.9990000128746033\n",
            "  - Threshold: 1.0\n",
            "\n",
            "Properties of lif2:\n",
            "  - Leaky (beta): 0.9990000128746033\n",
            "  - Threshold: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input-output pairs for the 8 combinations of the Gray code + 1\n",
        "X = torch.tensor(gray_codes[:-1], dtype=torch.float32)  # Inputs\n",
        "y = torch.tensor(gray_codes[1:], dtype=torch.float32)   # Outputs\n",
        "\n",
        "# Create DataLoader without repetition and no shuffle\n",
        "gray_code_test_dataset = TensorDataset(X, y)\n",
        "gray_code_test_loader = DataLoader(gray_code_test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Initialize counters for correct and incorrect predictions\n",
        "correct_predictions = 0\n",
        "incorrect_predictions = 0\n",
        "\n",
        "# Evaluate the model on all 8 unique combinations of the Gray code\n",
        "with torch.no_grad():\n",
        "    for data, targets in gray_code_test_loader:\n",
        "        data, targets = data.to(device), targets.to(device)  # Move data and targets to device\n",
        "\n",
        "        spk = model(data)\n",
        "        output = spk[-1] # Mean across time steps and round to nearest integer\n",
        "\n",
        "        # Check if the prediction matches the target\n",
        "        if (output == targets).all():\n",
        "            correct_predictions += 1\n",
        "        else:\n",
        "            incorrect_predictions += 1\n",
        "\n",
        "        # Print input, predicted, and target values\n",
        "        print(f\"Input: {data.cpu().numpy()}, Predicted: {output.cpu().numpy()}, Target: {targets.cpu().numpy()}\")\n",
        "\n",
        "# Calculate overall accuracy\n",
        "total_predictions = correct_predictions + incorrect_predictions\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "\n",
        "# Print summary of results\n",
        "print(f\"\\nCorrect Predictions: {correct_predictions}\")\n",
        "print(f\"Incorrect Predictions: {incorrect_predictions}\")\n",
        "print(f\"Overall Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utNBXv-Um4i9",
        "outputId": "77f6cb2b-0aa4-4479-f0fa-59f11fb89f83"
      },
      "id": "utNBXv-Um4i9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [[0. 0. 0.]], Predicted: [[0. 0. 1.]], Target: [[0. 0. 1.]]\n",
            "Input: [[0. 0. 1.]], Predicted: [[0. 1. 1.]], Target: [[0. 1. 1.]]\n",
            "Input: [[0. 1. 1.]], Predicted: [[0. 1. 0.]], Target: [[0. 1. 0.]]\n",
            "Input: [[0. 1. 0.]], Predicted: [[1. 1. 0.]], Target: [[1. 1. 0.]]\n",
            "Input: [[1. 1. 0.]], Predicted: [[1. 1. 1.]], Target: [[1. 1. 1.]]\n",
            "Input: [[1. 1. 1.]], Predicted: [[1. 0. 1.]], Target: [[1. 0. 1.]]\n",
            "Input: [[1. 0. 1.]], Predicted: [[1. 0. 0.]], Target: [[1. 0. 0.]]\n",
            "Input: [[1. 0. 0.]], Predicted: [[0. 0. 0.]], Target: [[0. 0. 0.]]\n",
            "\n",
            "Correct Predictions: 8\n",
            "Incorrect Predictions: 0\n",
            "Overall Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantized data and parameters"
      ],
      "metadata": {
        "id": "e46FtqjLEgdm"
      },
      "id": "e46FtqjLEgdm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the actual weights of the first layer\n",
        "print(\"First layer weights:\\n\", model.fc1.weight.data)\n",
        "\n",
        "# Print quantized weight scales for the first layer\n",
        "print(\"\\nFirst layer quantization scale:\\n\", model.fc1.quant_weight_scale())\n",
        "\n",
        "# Check the quantized weights range and values\n",
        "quantized_weights_fc1 = model.fc1.weight.data / model.fc1.quant_weight_scale()\n",
        "print(\"\\nQuantized values of first layer (scaled to integer range):\\n\", quantized_weights_fc1.int())\n",
        "\n",
        "# Repeat the process for the second layer\n",
        "print(\"\\nSecond layer weights:\\n\", model.fc2.weight.data)\n",
        "print(\"\\nSecond layer quantization scale:\\n\", model.fc2.quant_weight_scale())\n",
        "quantized_weights_fc2 = model.fc2.weight.data / model.fc2.quant_weight_scale()\n",
        "print(\"\\nQuantized values of second layer (scaled to integer range):\\n\", quantized_weights_fc2.int())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkshKHK7enWJ",
        "outputId": "bf30d20e-9f03-4139-816c-d3dc1e212791"
      },
      "id": "QkshKHK7enWJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First layer weights:\n",
            " tensor([[1.3052, 0.0000, 0.0000],\n",
            "        [0.0000, 1.1449, 0.0000],\n",
            "        [0.0000, 0.0000, 2.5882]])\n",
            "\n",
            "First layer quantization scale:\n",
            " tensor(0.0204, grad_fn=<DivBackward0>)\n",
            "\n",
            "Quantized values of first layer (scaled to integer range):\n",
            " tensor([[ 64,   0,   0],\n",
            "        [  0,  56,   0],\n",
            "        [  0,   0, 127]], dtype=torch.int32)\n",
            "\n",
            "Second layer weights:\n",
            " tensor([[-1.8717e+00,  2.0085e+00,  1.4848e-01],\n",
            "        [-1.0072e-01, -1.1686e+00,  1.2330e+00],\n",
            "        [ 7.3247e-05,  7.2581e-03,  6.7786e-01]])\n",
            "\n",
            "Second layer quantization scale:\n",
            " tensor(0.0158, grad_fn=<DivBackward0>)\n",
            "\n",
            "Quantized values of second layer (scaled to integer range):\n",
            " tensor([[-118,  127,    9],\n",
            "        [  -6,  -73,   77],\n",
            "        [   0,    0,   42]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def tensor_to_hex_and_bits_signed_8bit(tensor):\n",
        "    # First, we clamp the values to the 8-bit signed integer range (-128 to 127)\n",
        "    tensor = torch.clamp(tensor, -128, 127).int()\n",
        "\n",
        "    # Initialize lists to store hexadecimal values and bit arrays\n",
        "    hex_values = []\n",
        "    bit_arrays = []\n",
        "\n",
        "    # Iterate through the tensor, converting each value to 8-bit signed hex and bit array\n",
        "    for value in tensor.view(-1):  # Flatten the tensor for easy iteration\n",
        "        if value < 0:\n",
        "            # Convert negative number to its two's complement hex and bit representation\n",
        "            two_complement_value = (1 << 8) + value.item()  # 8-bit two's complement\n",
        "        else:\n",
        "            # Positive value (no two's complement required)\n",
        "            two_complement_value = value.item()\n",
        "\n",
        "        # Convert to hex, removing '0x' prefix and padding to 2 characters\n",
        "        hex_value = hex(two_complement_value)[2:].zfill(2)\n",
        "        hex_values.append(hex_value)\n",
        "\n",
        "        # Convert to 8-bit binary string and store the result as a string (instead of a list)\n",
        "        bit_array = bin(two_complement_value)[2:].zfill(8)  # 8-bit binary\n",
        "        bit_arrays.append(bit_array)\n",
        "\n",
        "    return hex_values, bit_arrays\n",
        "\n",
        "# Example usage:\n",
        "tensor = torch.tensor([10, -5, 127, -128, 45, -12])\n",
        "hex_result, bit_result = tensor_to_hex_and_bits_signed_8bit(tensor)\n",
        "\n",
        "print(\"Hexadecimal (2's complement) 8-bit signed values:\", hex_result)\n",
        "print(\"Bit arrays (2's complement) 8-bit signed values:\")\n",
        "for bits in bit_result:\n",
        "    print(bits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeUCTRedmITc",
        "outputId": "2e0aa5ec-4292-49c3-d477-4bbc75c00611"
      },
      "id": "DeUCTRedmITc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hexadecimal (2's complement) 8-bit signed values: ['0a', 'fb', '7f', '80', '2d', 'f4']\n",
            "Bit arrays (2's complement) 8-bit signed values:\n",
            "00001010\n",
            "11111011\n",
            "01111111\n",
            "10000000\n",
            "00101101\n",
            "11110100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize_tensor(tensor,tensor_min,tensor_max, a=-128, b=127):\n",
        "\n",
        "    # Normalize the tensor between a and b (e.g., -127 and 128)\n",
        "    tensor_normalized = (b - a) * (tensor - tensor_min) / (tensor_max - tensor_min) + a\n",
        "\n",
        "    return tensor_normalized\n",
        "\n",
        "def quantize_tensor(tensor, n_bits,tensor_min,tensor_max):\n",
        "    # Calculate the range for n-bit signed two's complement\n",
        "    min_val = -(2 ** (n_bits - 1))\n",
        "    max_val = (2 ** (n_bits - 1)) - 1\n",
        "\n",
        "    tensor_scaled=normalize_tensor(tensor,tensor_min,tensor_max,-max_val, max_val)\n",
        "\n",
        "    # Quantize to nearest integer\n",
        "    tensor_quantized = np.round(tensor_scaled)\n",
        "\n",
        "\n",
        "    # dequantize back to the original range\n",
        "    tensor_dequantized = ((tensor_quantized + max_val) / (max_val + max_val)) * (tensor_max - tensor_min) + tensor_min\n",
        "\n",
        "    return tensor_quantized, tensor_dequantized\n",
        "\n",
        "# Example usage\n",
        "# tensor = np.array([[0.5, 1.2, -0.3], [3.4, -2.1, 0.0]], dtype=np.float32)\n",
        "# n_bits = 8  # Example: 8-bit quantization\n",
        "\n",
        "# # Find the maximum absolute value\n",
        "# max_abs_value = np.max(np.abs(tensor))\n",
        "\n",
        "# quantized_tensor, dequantized_tensor = quantize_tensor(tensor, n_bits,-max_abs_value,max_abs_value)\n",
        "\n",
        "# print(\"Original Tensor:\")\n",
        "# print(tensor)\n",
        "# print(\"\\nQuantized Tensor:\")\n",
        "# print(quantized_tensor)\n",
        "# print(\"\\nDequantized Tensor (approximation of the original):\")\n",
        "# print(dequantized_tensor)\n",
        "\n",
        "# Get absolute values of both tensors\n",
        "overall_max = torch.max(torch.max(torch.abs(model.fc1.weight.data)),torch.max(torch.abs(model.fc2.weight.data)))\n",
        "\n",
        "n_bits = 6  # Example: 8-bit quantization\n",
        "\n",
        "# Print the weights of the first layer\n",
        "print(\"--------------------------------------------\\nFirst layer weights:\\n--------------------------------------------\")\n",
        "print(\"Original first layer weights:\\n\", model.fc1.weight.data)\n",
        "quantized_tensor_1, dequantized_tensor_1 = quantize_tensor(model.fc1.weight.data, n_bits,-overall_max,overall_max)\n",
        "# Print quantized weight scales for the first layer\n",
        "print(\"\\nFirst layer quantization:\\n\", quantized_tensor_1)\n",
        "print(\"\\nDequantized First layer (approximation of the original):\")\n",
        "print(dequantized_tensor_1)\n",
        "print(\"\\nhex_result - bit_result:\")\n",
        "hex_result, bit_result = tensor_to_hex_and_bits_signed_8bit(quantized_tensor_1)\n",
        "print(\"Hexadecimal (2's complement) 8-bit signed values:\", hex_result)\n",
        "print(\"Bit arrays (2's complement) 8-bit signed values:\")\n",
        "for bits in bit_result:\n",
        "    print(bits)\n",
        "\n",
        "# Print the weights of the second layer\n",
        "print(\"\\n\\n--------------------------------------------\\nSecond layer weights:\\n--------------------------------------------\")\n",
        "print(\"Original second layer weights:\\n\", model.fc2.weight.data)\n",
        "quantized_tensor_2, dequantized_tensor_2 = quantize_tensor(model.fc2.weight.data, n_bits,-overall_max,overall_max)\n",
        "# Print quantized weight scales for the first layer\n",
        "print(\"\\nFirst layer quantization:\\n\", quantized_tensor_2)\n",
        "print(\"\\nDequantized First layer (approximation of the original):\")\n",
        "print(dequantized_tensor_2)\n",
        "print(\"\\nhex_result - bit_result:\")\n",
        "hex_result, bit_result = tensor_to_hex_and_bits_signed_8bit(quantized_tensor_2)\n",
        "print(\"Hexadecimal (2's complement) 8-bit signed values:\", hex_result)\n",
        "print(\"Bit arrays (2's complement) 8-bit signed values:\")\n",
        "for bits in bit_result:\n",
        "    print(bits)\n",
        "\n",
        "\n",
        "decay_value=0.01\n",
        "# Print the quantized decay and threshold\n",
        "print(\"\\n\\n--------------------------------------------\\nDecay and Threshold:\\n--------------------------------------------\")\n",
        "print(\"Decay:\\n\", decay_value)\n",
        "quantized_decay_value, dequantized_decay_value = quantize_tensor(decay_value, n_bits,-overall_max,overall_max)\n",
        "# Print quantized weight scales for the first layer\n",
        "print(\"\\nquantized_decay_value:\\n\", quantized_decay_value)\n",
        "print(\"\\ndequantized_decay_value (approximation of the original):\")\n",
        "print(dequantized_decay_value)\n",
        "print(\"\\nhex_result - bit_result:\")\n",
        "hex_result, bit_result = tensor_to_hex_and_bits_signed_8bit(quantized_decay_value)\n",
        "print(\"Hexadecimal (2's complement) 8-bit signed values:\", hex_result)\n",
        "print(\"Bit arrays (2's complement) 8-bit signed values:\")\n",
        "for bits in bit_result:\n",
        "    print(bits)\n",
        "\n",
        "\n",
        "threshold=1\n",
        "print(\"Threshold:\\n\", threshold)\n",
        "quantized_threshold, dequantized_threshold = quantize_tensor(threshold, n_bits,-overall_max,overall_max)\n",
        "# Print quantized weight scales for the first layer\n",
        "print(\"\\quantized_threshold:\\n\", quantized_threshold)\n",
        "print(\"\\dequantized_threshold (approximation of the original):\")\n",
        "print(dequantized_threshold)\n",
        "print(\"\\nhex_result - bit_result:\")\n",
        "hex_result, bit_result = tensor_to_hex_and_bits_signed_8bit(quantized_threshold)\n",
        "print(\"Hexadecimal (2's complement) 8-bit signed values:\", hex_result)\n",
        "print(\"Bit arrays (2's complement) 8-bit signed values:\")\n",
        "for bits in bit_result:\n",
        "    print(bits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oik2O0BdwFz0",
        "outputId": "e3e10eb2-e79f-44be-dac4-df16943fdf3e"
      },
      "id": "Oik2O0BdwFz0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n",
            "First layer weights:\n",
            "--------------------------------------------\n",
            "Original first layer weights:\n",
            " tensor([[1.3052, 0.0000, 0.0000],\n",
            "        [0.0000, 1.1449, 0.0000],\n",
            "        [0.0000, 0.0000, 2.5882]])\n",
            "\n",
            "First layer quantization:\n",
            " tensor([[16.,  0.,  0.],\n",
            "        [ 0., 14.,  0.],\n",
            "        [ 0.,  0., 31.]])\n",
            "\n",
            "Dequantized First layer (approximation of the original):\n",
            "tensor([[1.3358, 0.0000, 0.0000],\n",
            "        [0.0000, 1.1689, 0.0000],\n",
            "        [0.0000, 0.0000, 2.5882]])\n",
            "\n",
            "hex_result - bit_result:\n",
            "Hexadecimal (2's complement) 8-bit signed values: ['10', '00', '00', '00', '0e', '00', '00', '00', '1f']\n",
            "Bit arrays (2's complement) 8-bit signed values:\n",
            "00010000\n",
            "00000000\n",
            "00000000\n",
            "00000000\n",
            "00001110\n",
            "00000000\n",
            "00000000\n",
            "00000000\n",
            "00011111\n",
            "\n",
            "\n",
            "--------------------------------------------\n",
            "Second layer weights:\n",
            "--------------------------------------------\n",
            "Original second layer weights:\n",
            " tensor([[-1.8717e+00,  2.0085e+00,  1.4848e-01],\n",
            "        [-1.0072e-01, -1.1686e+00,  1.2330e+00],\n",
            "        [ 7.3247e-05,  7.2581e-03,  6.7786e-01]])\n",
            "\n",
            "First layer quantization:\n",
            " tensor([[-22.,  24.,   2.],\n",
            "        [ -1., -14.,  15.],\n",
            "        [  0.,   0.,   8.]])\n",
            "\n",
            "Dequantized First layer (approximation of the original):\n",
            "tensor([[-1.8368,  2.0038,  0.1670],\n",
            "        [-0.0835, -1.1689,  1.2524],\n",
            "        [ 0.0000,  0.0000,  0.6679]])\n",
            "\n",
            "hex_result - bit_result:\n",
            "Hexadecimal (2's complement) 8-bit signed values: ['ea', '18', '02', 'ff', 'f2', '0f', '00', '00', '08']\n",
            "Bit arrays (2's complement) 8-bit signed values:\n",
            "11101010\n",
            "00011000\n",
            "00000010\n",
            "11111111\n",
            "11110010\n",
            "00001111\n",
            "00000000\n",
            "00000000\n",
            "00001000\n",
            "\n",
            "\n",
            "--------------------------------------------\n",
            "Decay and Threshold:\n",
            "--------------------------------------------\n",
            "Decay:\n",
            " 0.01\n",
            "\n",
            "quantized_decay_value:\n",
            " tensor(0.)\n",
            "\n",
            "dequantized_decay_value (approximation of the original):\n",
            "tensor(0.)\n",
            "\n",
            "hex_result - bit_result:\n",
            "Hexadecimal (2's complement) 8-bit signed values: ['00']\n",
            "Bit arrays (2's complement) 8-bit signed values:\n",
            "00000000\n",
            "Threshold:\n",
            " 1\n",
            "\\quantized_threshold:\n",
            " tensor(12.)\n",
            "\\dequantized_threshold (approximation of the original):\n",
            "tensor(1.0019)\n",
            "\n",
            "hex_result - bit_result:\n",
            "Hexadecimal (2's complement) 8-bit signed values: ['0c']\n",
            "Bit arrays (2's complement) 8-bit signed values:\n",
            "00001100\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}